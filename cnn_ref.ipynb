{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdd458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, MLDatasets, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb11f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 24, relu),          \u001b[90m# 240 parameters\u001b[39m\n",
       "  var\"#1#3\"(),\n",
       "  var\"#2#4\"(),\n",
       "  Dense(864 => 32, relu),               \u001b[90m# 27_680 parameters\u001b[39m\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m28_250 parameters, 110.953 KiB."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>24, relu),\n",
    "    x -> maxpool(x, (4,4)),\n",
    "\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(864, 32, relu),\n",
    "    Dense(32, 10),\n",
    "\n",
    "    softmax,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10182fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program has requested access to the data dependency MNIST.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: THE MNIST DATABASE of handwritten digits\n",
      "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
      "Website: http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "[LeCun et al., 1998a]\n",
      "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
      "    \"Gradient-based learning applied to document recognition.\"\n",
      "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
      "\n",
      "The files are available for download at the offical\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of MNIST aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./train\"?\n",
      "[y/n]\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./train\"?\n",
      "[y/n]\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./train\"?\n",
      "[y/n]\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./train\"?\n",
      "[y/n]\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./train\"?\n",
      "[y/n]\n",
      "This program has requested access to the data dependency MNIST.\n",
      "which is not currently installed. It can be installed automatically, and you will not see this message again.\n",
      "\n",
      "Dataset: THE MNIST DATABASE of handwritten digits\n",
      "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
      "Website: http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "[LeCun et al., 1998a]\n",
      "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
      "    \"Gradient-based learning applied to document recognition.\"\n",
      "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
      "\n",
      "The files are available for download at the offical\n",
      "website linked above. Note that using the data\n",
      "responsibly and respecting copyright remains your\n",
      "responsibility. The authors of MNIST aren't really\n",
      "explicit about any terms of use, so please read the\n",
      "website to make sure you want to download the\n",
      "dataset.\n",
      "\n",
      "\n",
      "\n",
      "Do you want to download the dataset from [\"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\", \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"] to \"./test\"?\n",
      "[y/n]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(features = [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], targets = [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = MNIST(split=:train, dir=\"./train\")[:]\n",
    "test_set  = MNIST(split=:test, dir=\"./test\")[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b941ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79-element DataLoader(::Tuple{Array{Float32, 4}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, batchsize=128)\n",
       "  with first element:\n",
       "  (28×28×1×128 Array{Float32, 4}, 10×128 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux: Data.DataLoader\n",
    "\n",
    "x_train = Flux.unsqueeze(train_set.features, 3)\n",
    "x_test = Flux.unsqueeze(test_set.features, 3)\n",
    "\n",
    "y_train = onehotbatch(train_set.targets, 0:9)\n",
    "y_test = onehotbatch(test_set.targets, 0:9)\n",
    "\n",
    "train_data = DataLoader((x_train, y_train); batchsize=128)\n",
    "test_data = DataLoader((x_test, y_test); batchsize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e45e50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(0.0075, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(model(x), y)\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "opt = ADAM(0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0227d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss: 0.04488531\n",
      "Epoch 1. loss: 0.02807118\n",
      "Epoch 1. loss: 0.025267005\n",
      "Epoch 1. loss: 0.029351374\n",
      "  27.863 s (192665 allocations: 26.80 GiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools: @btime\n",
    "\n",
    "number_epochs = 1\n",
    "@btime for i in 1:number_epochs \n",
    "    Flux.train!(loss, Flux.params(model), train_data, opt)\n",
    "    println(\"Epoch \", i, \". loss: \", loss(train_data.data[1], train_data.data[2])) \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6ba78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Vector{Float64}()\n",
    "\n",
    "for data in test_data\n",
    "    push!(acc, accuracy(data[1], data[2]))\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "496e1a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy:[0.9811902866242038]\n"
     ]
    }
   ],
   "source": [
    "println(\"Models accuracy:\", mean!([1.], acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7653d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
